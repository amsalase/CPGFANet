{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37b53f9-073c-4a8a-8b9d-c1858b752f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 2.2.6\n",
      "cv2: 4.13.0\n",
      "torch: 2.10.0+cu128\n",
      "cuda: 12.8\n",
      "gpu: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, cv2, torch\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"cv2:\", cv2.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda:\", torch.version.cuda)\n",
    "print(\"gpu:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4eb7979-80dd-4df5-8b3f-f2222e24a52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 363/363 [00:00<00:00, 489.26it/s, Materializing param=keypoint_encoder.encoder.4.weight]                            \n",
      "Processing pairs: 100%|██████████| 500/500 [04:21<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "{'out_root': '/workspace/dataset/dataset_2025/final_folder_II', 'warped_rgb_dir': '/workspace/dataset/dataset_2025/final_folder_II/warped_rgb', 'overlay_dir': '/workspace/dataset/dataset_2025/final_folder_II/overlay', 'heatmap_inliers_dir': '/workspace/dataset/dataset_2025/final_folder_II/heatmap_inliers', 'info_txt_dir': '/workspace/dataset/dataset_2025/final_folder_II/info_txt', 'summary_file': '/workspace/dataset/dataset_2025/final_folder_II/SUMMARY.txt', 'total_rgb_files': 500, 'missing_tir': 0, 'processed_pairs': 500, 'errors': 0, 'accepted_pairs': 365, 'accept_rate': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Batch RGB-TIR Registration (SuperGlue + RANSAC + Optional Undistort)\n",
    "# Outputs (same filename as input):\n",
    "#  - out_root/warped_rgb/<name>\n",
    "#  - out_root/overlay/<name>\n",
    "#  - out_root/heatmap_inliers/<name>\n",
    "#  - out_root/info_txt/<stem>.txt\n",
    "# Also writes: out_root/SUMMARY.txt\n",
    "# ============================================================\n",
    "\n",
    "# If needed (run once):\n",
    "# !pip -q install opencv-python transformers torch torchvision pillow matplotlib tqdm\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, SuperGlueForKeypointMatching\n",
    "\n",
    "# -----------------------------\n",
    "# OST reader (optional undistort)\n",
    "# -----------------------------\n",
    "def read_ost(ost_path: str):\n",
    "    lines = Path(ost_path).read_text(encoding=\"utf-8\", errors=\"ignore\").splitlines()\n",
    "\n",
    "    def find_line(name):\n",
    "        for i, l in enumerate(lines):\n",
    "            if l.strip().lower() == name.strip().lower():\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    iK = find_line(\"camera matrix\")\n",
    "    iD = find_line(\"distortion\")\n",
    "    if iK is None or iD is None:\n",
    "        raise ValueError(f\"No encontré 'camera matrix' o 'distortion' en {ost_path}\")\n",
    "\n",
    "    K = np.array([\n",
    "        [float(x) for x in lines[iK+1].split()],\n",
    "        [float(x) for x in lines[iK+2].split()],\n",
    "        [float(x) for x in lines[iK+3].split()],\n",
    "    ], dtype=np.float64)\n",
    "\n",
    "    dist = np.array([float(x) for x in lines[iD+1].split()], dtype=np.float64).reshape(1, -1)\n",
    "    return K, dist\n",
    "\n",
    "def undistort_if_available(img_bgr, K=None, dist=None, alpha=0.0):\n",
    "    if K is None or dist is None:\n",
    "        return img_bgr\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w, h), alpha, (w, h))\n",
    "    return cv2.undistort(img_bgr, K, dist, None, newK)\n",
    "\n",
    "# -----------------------------\n",
    "# Cross-modal preprocessing\n",
    "# -----------------------------\n",
    "def to_gray(img_bgr):\n",
    "    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY) if img_bgr.ndim == 3 else img_bgr\n",
    "\n",
    "def normalize_u8(img):\n",
    "    img = img.astype(np.float32)\n",
    "    img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "def clahe_u8(img_u8, clip=3.0, grid=(16, 16)):\n",
    "    c = cv2.createCLAHE(clipLimit=clip, tileGridSize=grid)\n",
    "    return c.apply(img_u8)\n",
    "\n",
    "def gradient_mag_u8(img_u8):\n",
    "    gx = cv2.Sobel(img_u8, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(img_u8, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    mag = cv2.magnitude(gx, gy)\n",
    "    mag = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    return mag.astype(np.uint8)\n",
    "\n",
    "def preprocess_cross_modal(img_bgr, do_grad=True):\n",
    "    g = to_gray(img_bgr)\n",
    "    g = normalize_u8(g)\n",
    "    g = clahe_u8(g, clip=3.0, grid=(16, 16))\n",
    "    if do_grad:\n",
    "        g = gradient_mag_u8(g)\n",
    "    return g\n",
    "\n",
    "def as_pil_rgb(img_bgr_or_u8):\n",
    "    if img_bgr_or_u8.ndim == 2:\n",
    "        img_rgb = cv2.cvtColor(img_bgr_or_u8, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        img_rgb = cv2.cvtColor(img_bgr_or_u8, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(img_rgb)\n",
    "\n",
    "# -----------------------------\n",
    "# SuperGlue (loaded once)\n",
    "# -----------------------------\n",
    "class SuperGlueHF:\n",
    "    def __init__(self, ckpt=\"magic-leap-community/superglue_outdoor\", device=None):\n",
    "        self.processor = AutoImageProcessor.from_pretrained(ckpt)\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = SuperGlueForKeypointMatching.from_pretrained(ckpt).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def match(self, img0_pil, img1_pil, threshold=0.35, max_matches=1500):\n",
    "        images = [[img0_pil, img1_pil]]\n",
    "        inputs = self.processor(images, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model(**inputs)\n",
    "\n",
    "        image_sizes = [[(img.height, img.width) for img in pair] for pair in images]\n",
    "        results = self.processor.post_process_keypoint_matching(outputs, image_sizes, threshold=threshold)\n",
    "        r = results[0]\n",
    "\n",
    "        k0 = r[\"keypoints0\"].detach().cpu().numpy().astype(np.float32)  # img0\n",
    "        k1 = r[\"keypoints1\"].detach().cpu().numpy().astype(np.float32)  # img1\n",
    "        sc = r[\"matching_scores\"].detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "        if len(sc) > max_matches:\n",
    "            idx = np.argsort(-sc)[:max_matches]\n",
    "            k0, k1, sc = k0[idx], k1[idx], sc[idx]\n",
    "\n",
    "        return k0, k1, sc\n",
    "\n",
    "# -----------------------------\n",
    "# Robust estimation + QC\n",
    "# -----------------------------\n",
    "def estimate_affine_ransac(k_src, k_dst, thr=5.0):\n",
    "    if k_src is None or len(k_src) < 8:\n",
    "        return None, 0.0, None\n",
    "    M, inliers = cv2.estimateAffinePartial2D(\n",
    "        k_src, k_dst, method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=thr, maxIters=5000, confidence=0.995\n",
    "    )\n",
    "    if M is None or inliers is None:\n",
    "        return None, 0.0, None\n",
    "    return M.astype(np.float32), float(inliers.mean()), inliers.astype(bool).ravel()\n",
    "\n",
    "def estimate_homography_ransac(k_src, k_dst, thr=5.0):\n",
    "    if k_src is None or len(k_src) < 4:\n",
    "        return None, 0.0, None\n",
    "    H, inliers = cv2.findHomography(\n",
    "        k_src, k_dst, method=cv2.RANSAC,\n",
    "        ransacReprojThreshold=thr, maxIters=5000, confidence=0.995\n",
    "    )\n",
    "    if H is None or inliers is None:\n",
    "        return None, 0.0, None\n",
    "    return H.astype(np.float32), float(inliers.mean()), inliers.astype(bool).ravel()\n",
    "\n",
    "def reprojection_error_homography(H, k_src, k_dst, inlier_mask=None):\n",
    "    if H is None:\n",
    "        return np.inf, np.inf\n",
    "    if inlier_mask is None:\n",
    "        inlier_mask = np.ones(len(k_src), dtype=bool)\n",
    "    src = k_src[inlier_mask]\n",
    "    dst = k_dst[inlier_mask]\n",
    "    if len(src) < 4:\n",
    "        return np.inf, np.inf\n",
    "    src_h = cv2.convertPointsToHomogeneous(src).reshape(-1, 3)\n",
    "    proj = (H @ src_h.T).T\n",
    "    proj = proj[:, :2] / proj[:, 2:3]\n",
    "    err = np.linalg.norm(proj - dst, axis=1)\n",
    "    return float(np.mean(err)), float(np.median(err))\n",
    "\n",
    "def qc_pass(num_matches, inlier_ratio, reproj_median,\n",
    "            min_matches=40, min_inlier=0.40, max_median_err=4.0):\n",
    "    return (num_matches >= min_matches) and (inlier_ratio >= min_inlier) and (reproj_median <= max_median_err)\n",
    "\n",
    "# -----------------------------\n",
    "# Heatmap utilities\n",
    "# -----------------------------\n",
    "def make_keypoint_heatmap(h, w, pts_xy, sigma=18, weights=None):\n",
    "    heat = np.zeros((h, w), dtype=np.float32)\n",
    "    if pts_xy is None or len(pts_xy) == 0:\n",
    "        return heat\n",
    "\n",
    "    pts = np.round(pts_xy).astype(int)\n",
    "    if weights is None:\n",
    "        weights = np.ones((len(pts),), dtype=np.float32)\n",
    "    else:\n",
    "        weights = weights.astype(np.float32)\n",
    "\n",
    "    for (x, y), wgt in zip(pts, weights):\n",
    "        if 0 <= x < w and 0 <= y < h:\n",
    "            heat[y, x] += float(wgt)\n",
    "\n",
    "    k = int(6*sigma + 1)\n",
    "    if k % 2 == 0:\n",
    "        k += 1\n",
    "    heat = cv2.GaussianBlur(heat, (k, k), sigmaX=sigma, sigmaY=sigma)\n",
    "\n",
    "    if heat.max() > 0:\n",
    "        heat = heat / heat.max()\n",
    "    return heat\n",
    "\n",
    "def overlay_heatmap_on_image(img_bgr, heat01, alpha=0.45):\n",
    "    heat_u8 = (heat01 * 255).astype(np.uint8)\n",
    "    heat_color = cv2.applyColorMap(heat_u8, cv2.COLORMAP_JET)  # BGR\n",
    "    out = cv2.addWeighted(img_bgr, 1 - alpha, heat_color, alpha, 0)\n",
    "    return out, heat_color\n",
    "\n",
    "# -----------------------------\n",
    "# Per-pair processing (save outputs)\n",
    "# -----------------------------\n",
    "def process_one_pair(\n",
    "    tir_path: Path,\n",
    "    rgb_path: Path,\n",
    "    out_warped_dir: Path,\n",
    "    out_overlay_dir: Path,\n",
    "    out_heat_dir: Path,\n",
    "    out_txt_dir: Path,\n",
    "    matcher: SuperGlueHF,\n",
    "    K_tir=None, d_tir=None, K_rgb=None, d_rgb=None,\n",
    "    score_thr=0.35, ransac_thr=5.0,\n",
    "    min_matches=40, min_inlier=0.40, max_median_err=4.0,\n",
    "):\n",
    "    name = rgb_path.name\n",
    "    stem = rgb_path.stem\n",
    "\n",
    "    tir_bgr = cv2.imread(str(tir_path), cv2.IMREAD_COLOR)\n",
    "    rgb_bgr = cv2.imread(str(rgb_path), cv2.IMREAD_COLOR)\n",
    "    if tir_bgr is None or rgb_bgr is None:\n",
    "        raise ValueError(f\"Error leyendo: {tir_path} o {rgb_path}\")\n",
    "\n",
    "    # undistort optional\n",
    "    if K_tir is not None and d_tir is not None:\n",
    "        tir_bgr = undistort_if_available(tir_bgr, K_tir, d_tir, alpha=0.0)\n",
    "    if K_rgb is not None and d_rgb is not None:\n",
    "        rgb_bgr = undistort_if_available(rgb_bgr, K_rgb, d_rgb, alpha=0.0)\n",
    "\n",
    "    # preprocess\n",
    "    tir_p = preprocess_cross_modal(tir_bgr, do_grad=True)\n",
    "    rgb_p = preprocess_cross_modal(rgb_bgr, do_grad=True)\n",
    "    tir_pil = as_pil_rgb(tir_p)\n",
    "    rgb_pil = as_pil_rgb(rgb_p)\n",
    "\n",
    "    # match (keypoints0=tIR, keypoints1=RGB)\n",
    "    k_tir, k_rgb, sc = matcher.match(tir_pil, rgb_pil, threshold=score_thr, max_matches=1500)\n",
    "    num_matches = int(len(sc))\n",
    "\n",
    "    # warp RGB->TIR : src=RGB, dst=TIR\n",
    "    k0 = k_rgb\n",
    "    k1 = k_tir\n",
    "\n",
    "    M_aff, inl_aff, mask_aff = estimate_affine_ransac(k0, k1, thr=ransac_thr)\n",
    "    H, inl_h, mask_h = estimate_homography_ransac(k0, k1, thr=ransac_thr)\n",
    "    mean_err, med_err = reprojection_error_homography(H, k0, k1, mask_h)\n",
    "\n",
    "    ok_H = qc_pass(num_matches, inl_h, med_err, min_matches, min_inlier, max_median_err)\n",
    "    ok_A = (num_matches >= min_matches) and (inl_aff >= min_inlier)\n",
    "\n",
    "    if ok_A and ok_H:\n",
    "        use_H = (med_err <= max_median_err * 0.7) and (inl_h > inl_aff + 0.05)\n",
    "    elif ok_H:\n",
    "        use_H = True\n",
    "    else:\n",
    "        use_H = False\n",
    "\n",
    "    accepted = bool(ok_A or ok_H)\n",
    "\n",
    "    # warp\n",
    "    h, w = tir_bgr.shape[:2]\n",
    "    warped_rgb = None\n",
    "    model_used = \"NONE\"\n",
    "    if use_H and H is not None:\n",
    "        warped_rgb = cv2.warpPerspective(rgb_bgr, H, (w, h), flags=cv2.INTER_LINEAR)\n",
    "        model_used = \"H\"\n",
    "    elif M_aff is not None:\n",
    "        warped_rgb = cv2.warpAffine(rgb_bgr, M_aff, (w, h), flags=cv2.INTER_LINEAR)\n",
    "        model_used = \"A\"\n",
    "\n",
    "    # overlay\n",
    "    tir_gray = cv2.cvtColor(tir_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    tir_vis = cv2.cvtColor(tir_gray, cv2.COLOR_GRAY2BGR)\n",
    "    overlay = cv2.addWeighted(tir_vis, 0.5, warped_rgb, 0.5, 0.0) if warped_rgb is not None else tir_vis\n",
    "\n",
    "    # heatmap (H inliers in TIR space)\n",
    "    if (mask_h is not None) and (len(k1) > 0) and (len(mask_h) == len(k1)):\n",
    "        pts_inl = k1[mask_h]\n",
    "        w_inl = sc[mask_h] if len(sc) == len(mask_h) else None\n",
    "    else:\n",
    "        pts_inl = np.zeros((0, 2), dtype=np.float32)\n",
    "        w_inl = None\n",
    "\n",
    "    heat_inl = make_keypoint_heatmap(h, w, pts_inl, sigma=18, weights=w_inl)\n",
    "    heat_overlay_inl, _ = overlay_heatmap_on_image(overlay.copy(), heat_inl, alpha=0.45)\n",
    "\n",
    "    # Save images with SAME name\n",
    "    out_warp_path = out_warped_dir / name\n",
    "    out_ovr_path = out_overlay_dir / name\n",
    "    out_heat_path = out_heat_dir / name\n",
    "    out_txt_path = out_txt_dir / f\"{stem}.txt\"\n",
    "\n",
    "    # Keep filename parity even if warp fails (black placeholder)\n",
    "    if warped_rgb is None:\n",
    "        warped_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "    cv2.imwrite(str(out_warp_path), warped_rgb)\n",
    "    cv2.imwrite(str(out_ovr_path), overlay)\n",
    "    cv2.imwrite(str(out_heat_path), heat_overlay_inl)\n",
    "\n",
    "    # Write TXT (same stem)\n",
    "    txt = []\n",
    "    txt.append(f\"name: {name}\")\n",
    "    txt.append(f\"rgb_path: {rgb_path}\")\n",
    "    txt.append(f\"tir_path: {tir_path}\")\n",
    "    txt.append(\"---- thresholds ----\")\n",
    "    txt.append(f\"score_thr: {score_thr}\")\n",
    "    txt.append(f\"ransac_thr: {ransac_thr}\")\n",
    "    txt.append(f\"min_matches: {min_matches}\")\n",
    "    txt.append(f\"min_inlier: {min_inlier}\")\n",
    "    txt.append(f\"max_median_err: {max_median_err}\")\n",
    "    txt.append(\"---- metrics ----\")\n",
    "    txt.append(f\"num_matches: {num_matches}\")\n",
    "    txt.append(f\"inlier_aff: {inl_aff:.6f}\")\n",
    "    txt.append(f\"inlier_H: {inl_h:.6f}\")\n",
    "    txt.append(f\"H_median_err_px: {med_err:.6f}\")\n",
    "    txt.append(f\"ok_A: {ok_A}\")\n",
    "    txt.append(f\"ok_H: {ok_H}\")\n",
    "    txt.append(f\"accepted: {accepted}\")\n",
    "    txt.append(f\"model_used_for_warp: {model_used}\")\n",
    "    txt.append(\"---- outputs ----\")\n",
    "    txt.append(f\"warped_rgb: {out_warp_path}\")\n",
    "    txt.append(f\"overlay: {out_ovr_path}\")\n",
    "    txt.append(f\"heatmap_inliers: {out_heat_path}\")\n",
    "    out_txt_path.write_text(\"\\n\".join(txt), encoding=\"utf-8\")\n",
    "\n",
    "    return accepted, model_used, num_matches, inl_h, med_err\n",
    "\n",
    "# -----------------------------\n",
    "# Batch runner\n",
    "# -----------------------------\n",
    "def run_batch(\n",
    "    rgb_dir: str,\n",
    "    tir_dir: str,\n",
    "    out_root: str,\n",
    "    ost_rgb: str = None,\n",
    "    ost_tir: str = None,\n",
    "    score_thr: float = 0.35,\n",
    "    ransac_thr: float = 5.0,\n",
    "    min_matches: int = 40,\n",
    "    min_inlier: float = 0.40,\n",
    "    max_median_err: float = 4.0,\n",
    "    exts=(\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tif\", \".tiff\"),\n",
    "):\n",
    "    rgb_dir = Path(rgb_dir)\n",
    "    tir_dir = Path(tir_dir)\n",
    "    out_root = Path(out_root)\n",
    "\n",
    "    out_warped_dir = out_root / \"warped_rgb\"\n",
    "    out_overlay_dir = out_root / \"overlay\"\n",
    "    out_heat_dir = out_root / \"heatmap_inliers\"\n",
    "    out_txt_dir = out_root / \"info_txt\"\n",
    "\n",
    "    for d in (out_warped_dir, out_overlay_dir, out_heat_dir, out_txt_dir):\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # optional intrinsics\n",
    "    K_rgb = d_rgb = K_tir = d_tir = None\n",
    "    if ost_rgb and Path(ost_rgb).exists():\n",
    "        K_rgb, d_rgb = read_ost(ost_rgb)\n",
    "    if ost_tir and Path(ost_tir).exists():\n",
    "        K_tir, d_tir = read_ost(ost_tir)\n",
    "\n",
    "    # list RGB files\n",
    "    rgb_files = []\n",
    "    for ext in exts:\n",
    "        rgb_files.extend(rgb_dir.glob(f\"*{ext}\"))\n",
    "    rgb_files = sorted(rgb_files)\n",
    "\n",
    "    if not rgb_files:\n",
    "        raise ValueError(f\"No encontré imágenes en {rgb_dir}\")\n",
    "\n",
    "    matcher = SuperGlueHF()\n",
    "\n",
    "    missing = 0\n",
    "    processed = 0\n",
    "    accepted_count = 0\n",
    "    used_H = 0\n",
    "    used_A = 0\n",
    "    failed = 0\n",
    "\n",
    "    for rgb_path in tqdm(rgb_files, desc=\"Processing pairs\"):\n",
    "        tir_path = tir_dir / rgb_path.name\n",
    "        if not tir_path.exists():\n",
    "            missing += 1\n",
    "            # write txt for missing\n",
    "            (out_txt_dir / f\"{rgb_path.stem}.txt\").write_text(\n",
    "                f\"name: {rgb_path.name}\\nstatus: MISSING_TIR\\nexpected_tir_path: {tir_path}\\n\",\n",
    "                encoding=\"utf-8\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            accepted, model_used, num_matches, inl_h, med_err = process_one_pair(\n",
    "                tir_path=tir_path,\n",
    "                rgb_path=rgb_path,\n",
    "                out_warped_dir=out_warped_dir,\n",
    "                out_overlay_dir=out_overlay_dir,\n",
    "                out_heat_dir=out_heat_dir,\n",
    "                out_txt_dir=out_txt_dir,\n",
    "                matcher=matcher,\n",
    "                K_tir=K_tir, d_tir=d_tir,\n",
    "                K_rgb=K_rgb, d_rgb=d_rgb,\n",
    "                score_thr=score_thr,\n",
    "                ransac_thr=ransac_thr,\n",
    "                min_matches=min_matches,\n",
    "                min_inlier=min_inlier,\n",
    "                max_median_err=max_median_err,\n",
    "            )\n",
    "            processed += 1\n",
    "            if accepted:\n",
    "                accepted_count += 1\n",
    "            if model_used == \"H\":\n",
    "                used_H += 1\n",
    "            elif model_used == \"A\":\n",
    "                used_A += 1\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "            (out_txt_dir / f\"{rgb_path.stem}.txt\").write_text(\n",
    "                f\"name: {rgb_path.name}\\nstatus: ERROR\\nerror: {repr(e)}\\n\",\n",
    "                encoding=\"utf-8\"\n",
    "            )\n",
    "\n",
    "    summary = []\n",
    "    summary.append(f\"rgb_dir: {rgb_dir}\")\n",
    "    summary.append(f\"tir_dir: {tir_dir}\")\n",
    "    summary.append(f\"total_rgb_files: {len(rgb_files)}\")\n",
    "    summary.append(f\"missing_tir: {missing}\")\n",
    "    summary.append(f\"processed_pairs: {processed}\")\n",
    "    summary.append(f\"errors: {failed}\")\n",
    "    summary.append(f\"accepted_pairs: {accepted_count}\")\n",
    "    summary.append(f\"accept_rate: {accepted_count/max(1,processed):.4f}\")\n",
    "    summary.append(f\"warps_used_H: {used_H}\")\n",
    "    summary.append(f\"warps_used_A: {used_A}\")\n",
    "    summary.append(\"---- thresholds ----\")\n",
    "    summary.append(f\"score_thr: {score_thr}\")\n",
    "    summary.append(f\"ransac_thr: {ransac_thr}\")\n",
    "    summary.append(f\"min_matches: {min_matches}\")\n",
    "    summary.append(f\"min_inlier: {min_inlier}\")\n",
    "    summary.append(f\"max_median_err: {max_median_err}\")\n",
    "    (out_root / \"SUMMARY.txt\").write_text(\"\\n\".join(summary), encoding=\"utf-8\")\n",
    "\n",
    "    return {\n",
    "        \"out_root\": str(out_root),\n",
    "        \"warped_rgb_dir\": str(out_warped_dir),\n",
    "        \"overlay_dir\": str(out_overlay_dir),\n",
    "        \"heatmap_inliers_dir\": str(out_heat_dir),\n",
    "        \"info_txt_dir\": str(out_txt_dir),\n",
    "        \"summary_file\": str(out_root / \"SUMMARY.txt\"),\n",
    "        \"total_rgb_files\": len(rgb_files),\n",
    "        \"missing_tir\": missing,\n",
    "        \"processed_pairs\": processed,\n",
    "        \"errors\": failed,\n",
    "        \"accepted_pairs\": accepted_count,\n",
    "        \"accept_rate\": accepted_count/max(1,processed),\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG: EDIT THESE PATHS\n",
    "# ============================================================\n",
    "RGB_DIR  = \"/workspace/dataset/dataset_2025/rgb_org/\"\n",
    "TIR_DIR  = \"/workspace/dataset/dataset_2025/tir_v2/\"\n",
    "OUT_ROOT = \"/workspace/dataset/dataset_2025/final_folder_II/\"\n",
    "\n",
    "# Optional (set to None if you don't have intrinsics files):\n",
    "OST_RGB = \"/workspace/ost_rgb.txt\"  # e.g. \"/content/ost_rgb.txt\"\n",
    "OST_TIR = \"/workspace/ost_tir.txt\"  # e.g. \"/content/ost_tir.txt\"\n",
    "\n",
    "# Thresholds (use your current settings):\n",
    "SCORE_THR = 0.35\n",
    "RANSAC_THR = 5.0\n",
    "MIN_MATCHES = 40\n",
    "MIN_INLIER = 0.40\n",
    "MAX_MED_ERR = 4.0\n",
    "\n",
    "# ============================================================\n",
    "# RUN\n",
    "# ============================================================\n",
    "results = run_batch(\n",
    "    rgb_dir=RGB_DIR,\n",
    "    tir_dir=TIR_DIR,\n",
    "    out_root=OUT_ROOT,\n",
    "    ost_rgb=OST_RGB,\n",
    "    ost_tir=OST_TIR,\n",
    "    score_thr=SCORE_THR,\n",
    "    ransac_thr=RANSAC_THR,\n",
    "    min_matches=MIN_MATCHES,\n",
    "    min_inlier=MIN_INLIER,\n",
    "    max_median_err=MAX_MED_ERR,\n",
    ")\n",
    "\n",
    "print(\"DONE\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e58a5-ca4a-4526-88f5-4313dea3ba71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
